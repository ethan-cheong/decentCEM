2024-11-09 17:07:15,374 - INFO - 
{'ctrl_cfg': {'cem_cfg': {'cem_type': 'POPLINA-INIT',
                          'debug_optimizer': False,
                          'debug_policy': False,
                          'discriminator_act_type': 'leaky_relu',
                          'discriminator_ent_lambda': 0.001,
                          'discriminator_epochs': 40,
                          'discriminator_gradient_penalty_coeff': 10.0,
                          'discriminator_lr': 0.003,
                          'discriminator_minibatch_size': 64,
                          'discriminator_network_shape': [64, 64],
                          'discriminator_norm_type': None,
                          'ensemble_size': 5,
                          'eval_cem_policy': True,
                          'eval_ctrl_type': 'MPC',
                          'gan_type': 'GAN',
                          'init_var': 0.25,
                          'loss_type': 'reverse',
                          'loss_weight': [1, 1],
                          'minibatch_size': 64,
                          'pct_testset': 0.2,
                          'policy_epochs': 100,
                          'policy_lr': 0.001,
                          'policy_lr_weight': 0.2,
                          'policy_network_shape': [64, 64],
                          'policy_weight_decay': 1e-05,
                          'pwcem_init_mean': True,
                          'return_best_sample': False,
                          'seed': 1234,
                          'test_policy': 1,
                          'test_policy_epochs': 5,
                          'training_scheme': 'BC-AR',
                          'training_top_k': 50,
                          'use_prev_sol': True,
                          'zero_weight': 'No'},
              'env': <mbbl.env.gym_env.walker.env object at 0x7f4a8c875f10>,
              'gbp_cfg': DotMap(plan_iter=5, lr=0.03, gbp_type=3),
              'get_display_obs_fn': None,
              'il_cfg': DotMap(expert_amc_dir='/home', use_gt_dynamics=0),
              'mb_cfg': {'activation': 'swish',
                         'do_benchmarking': 'no',
                         'dynamics_lr': 0.001,
                         'mb_batch_size': 32,
                         'mb_epochs': 100,
                         'normalization': 'none'},
              'opt_cfg': {'ac_cost_fn': <function AntConfigModule.ac_cost_fn at 0x7f4a8c87d560>,
                          'cfg': {'alpha': 0.1,
                                  'max_iters': 5,
                                  'num_elites': 50,
                                  'popsize': 500},
                          'init_var': 0.25,
                          'mb_cfg': {'activation': 'swish',
                                     'do_benchmarking': 'no',
                                     'dynamics_lr': 0.001,
                                     'mb_batch_size': 32,
                                     'mb_epochs': 100,
                                     'normalization': 'none'},
                          'mode': 'POPLIN-A',
                          'obs_cost_fn': <function AntConfigModule.obs_cost_fn at 0x7f4a8c87d4d0>,
                          'plan_hor': 30},
              'prop_cfg': {'mode': 'E',
                           'model_init_cfg': {'model_class': <class 'dmbrl.modeling.models.BNN.BNN'>,
                                              'model_constructor': <bound method AntConfigModule.nn_constructor of <gym_ant.AntConfigModule object at 0x7f4a8c875d90>>,
                                              'num_nets': 5},
                           'model_train_cfg': {'epochs': 5},
                           'npart': 1,
                           'obs_ac_cost_fn': None,
                           'obs_postproc': <function AntConfigModule.obs_postproc at 0x7f4a8c87d3b0>,
                           'obs_preproc': <function AntConfigModule.obs_preproc at 0x7f4a8c87d320>,
                           'targ_proc': <function AntConfigModule.targ_proc at 0x7f4a8c87d440>}},
 'exp_cfg': {'exp_cfg': {'ninit_rollouts': 0,
                         'nrollouts_per_iter': 1,
                         'ntrain_iters': 50},
             'log_cfg': DotMap(logdir='log/poplina'),
             'sim_cfg': {'env': <mbbl.env.gym_env.walker.env object at 0x7f4a8c875f10>,
                         'seed_eval': 0,
                         'seed_train': 1,
                         'task_hor': 200}}}
2024-11-09 17:07:15,375 - INFO - Using seed 1 for training
2024-11-09 17:07:15,375 - INFO - Created an ensemble of 5 neural networks with variance predictions.
2024-11-09 17:07:16,734 - INFO - policy training learning rate: 0.001
2024-11-09 17:07:21,853 - INFO - Created an MPC controller, prop mode E, 1 particles. Ignoring variance.
2024-11-09 17:07:21,853 - INFO - Trajectory prediction logging is disabled.
2024-11-09 17:26:32,267 - INFO - 
{'ctrl_cfg': {'cem_cfg': {'cem_type': 'POPLINA-INIT',
                          'debug_optimizer': False,
                          'debug_policy': False,
                          'discriminator_act_type': 'leaky_relu',
                          'discriminator_ent_lambda': 0.001,
                          'discriminator_epochs': 40,
                          'discriminator_gradient_penalty_coeff': 10.0,
                          'discriminator_lr': 0.003,
                          'discriminator_minibatch_size': 64,
                          'discriminator_network_shape': [64, 64],
                          'discriminator_norm_type': None,
                          'ensemble_size': 5,
                          'eval_cem_policy': True,
                          'eval_ctrl_type': 'MPC',
                          'gan_type': 'GAN',
                          'init_var': 0.25,
                          'loss_type': 'reverse',
                          'loss_weight': [1, 1],
                          'minibatch_size': 64,
                          'pct_testset': 0.2,
                          'policy_epochs': 100,
                          'policy_lr': 0.001,
                          'policy_lr_weight': 0.2,
                          'policy_network_shape': [64, 64],
                          'policy_weight_decay': 1e-05,
                          'pwcem_init_mean': True,
                          'return_best_sample': False,
                          'seed': 1234,
                          'test_policy': 1,
                          'test_policy_epochs': 5,
                          'training_scheme': 'BC-AR',
                          'training_top_k': 50,
                          'use_prev_sol': True,
                          'zero_weight': 'No'},
              'env': <mbbl.env.gym_env.walker.env object at 0x7f57dc98ee90>,
              'gbp_cfg': DotMap(plan_iter=5, lr=0.03, gbp_type=3),
              'get_display_obs_fn': None,
              'il_cfg': DotMap(expert_amc_dir='/home', use_gt_dynamics=0),
              'mb_cfg': {'activation': 'swish',
                         'do_benchmarking': 'no',
                         'dynamics_lr': 0.001,
                         'mb_batch_size': 32,
                         'mb_epochs': 100,
                         'normalization': 'none'},
              'opt_cfg': {'ac_cost_fn': <function AntConfigModule.ac_cost_fn at 0x7f57dc9975f0>,
                          'cfg': {'alpha': 0.1,
                                  'max_iters': 5,
                                  'num_elites': 50,
                                  'popsize': 500},
                          'init_var': 0.25,
                          'mb_cfg': {'activation': 'swish',
                                     'do_benchmarking': 'no',
                                     'dynamics_lr': 0.001,
                                     'mb_batch_size': 32,
                                     'mb_epochs': 100,
                                     'normalization': 'none'},
                          'mode': 'POPLIN-A',
                          'obs_cost_fn': <function AntConfigModule.obs_cost_fn at 0x7f57dc997560>,
                          'plan_hor': 30},
              'prop_cfg': {'mode': 'E',
                           'model_init_cfg': {'model_class': <class 'dmbrl.modeling.models.BNN.BNN'>,
                                              'model_constructor': <bound method AntConfigModule.nn_constructor of <gym_ant.AntConfigModule object at 0x7f57dc98ed10>>,
                                              'num_nets': 5},
                           'model_train_cfg': {'epochs': 5},
                           'npart': 1,
                           'obs_ac_cost_fn': None,
                           'obs_postproc': <function AntConfigModule.obs_postproc at 0x7f57dc997440>,
                           'obs_preproc': <function AntConfigModule.obs_preproc at 0x7f57dc9973b0>,
                           'targ_proc': <function AntConfigModule.targ_proc at 0x7f57dc9974d0>}},
 'exp_cfg': {'exp_cfg': {'ninit_rollouts': 0,
                         'nrollouts_per_iter': 1,
                         'ntrain_iters': 2},
             'log_cfg': DotMap(logdir='log/poplina'),
             'sim_cfg': {'env': <mbbl.env.gym_env.walker.env object at 0x7f57dc98ee90>,
                         'seed_eval': 0,
                         'seed_train': 1,
                         'task_hor': 200}}}
2024-11-09 17:26:32,268 - INFO - Using seed 1 for training
2024-11-09 17:26:32,268 - INFO - Created an ensemble of 5 neural networks with variance predictions.
2024-11-09 17:26:33,595 - INFO - policy training learning rate: 0.001
2024-11-09 17:26:38,727 - INFO - Created an MPC controller, prop mode E, 1 particles. Ignoring variance.
2024-11-09 17:26:38,727 - INFO - Trajectory prediction logging is disabled.
2024-11-09 22:13:27,219 - INFO - 
{'ctrl_cfg': {'cem_cfg': {'cem_type': 'POPLINP-SEP',
                          'debug_optimizer': False,
                          'debug_policy': False,
                          'discriminator_act_type': 'leaky_relu',
                          'discriminator_ent_lambda': 0.001,
                          'discriminator_epochs': 40,
                          'discriminator_gradient_penalty_coeff': 10.0,
                          'discriminator_lr': 0.003,
                          'discriminator_minibatch_size': 64,
                          'discriminator_network_shape': [64, 64],
                          'discriminator_norm_type': None,
                          'ensemble_size': 5,
                          'eval_cem_policy': True,
                          'eval_ctrl_type': 'MPC',
                          'gan_type': 'GAN',
                          'init_var': 0.1,
                          'loss_type': 'reverse',
                          'loss_weight': [1, 1],
                          'minibatch_size': 64,
                          'pct_testset': 0.2,
                          'policy_epochs': 100,
                          'policy_lr': 0.001,
                          'policy_lr_weight': 0.2,
                          'policy_network_shape': [32],
                          'policy_weight_decay': 1e-05,
                          'pwcem_init_mean': True,
                          'return_best_sample': False,
                          'seed': 1234,
                          'test_policy': 1,
                          'test_policy_epochs': 1,
                          'training_scheme': 'AVG-R',
                          'training_top_k': 50,
                          'use_prev_sol': True,
                          'zero_weight': 'No'},
              'env': <mbbl.env.gym_env.walker.env object at 0x7843ccd95b10>,
              'gbp_cfg': DotMap(plan_iter=5, lr=0.03, gbp_type=3),
              'get_display_obs_fn': None,
              'il_cfg': DotMap(expert_amc_dir='/home', use_gt_dynamics=0),
              'mb_cfg': {'activation': 'swish',
                         'do_benchmarking': 'no',
                         'dynamics_lr': 0.001,
                         'mb_batch_size': 32,
                         'mb_epochs': 100,
                         'normalization': 'none'},
              'opt_cfg': {'ac_cost_fn': <function AntConfigModule.ac_cost_fn at 0x7843ccd9f5f0>,
                          'cfg': {'alpha': 0.1,
                                  'max_iters': 5,
                                  'num_elites': 50,
                                  'popsize': 500},
                          'init_var': 0.1,
                          'mb_cfg': {'activation': 'swish',
                                     'do_benchmarking': 'no',
                                     'dynamics_lr': 0.001,
                                     'mb_batch_size': 32,
                                     'mb_epochs': 100,
                                     'normalization': 'none'},
                          'mode': 'POPLIN-P',
                          'obs_cost_fn': <function AntConfigModule.obs_cost_fn at 0x7843ccd9f560>,
                          'plan_hor': 30},
              'prop_cfg': {'mode': 'E',
                           'model_init_cfg': {'model_class': <class 'dmbrl.modeling.models.BNN.BNN'>,
                                              'model_constructor': <bound method AntConfigModule.nn_constructor of <gym_ant.AntConfigModule object at 0x7843ccd99cd0>>,
                                              'num_nets': 5},
                           'model_train_cfg': {'epochs': 5},
                           'npart': 1,
                           'obs_ac_cost_fn': None,
                           'obs_postproc': <function AntConfigModule.obs_postproc at 0x7843ccd9f440>,
                           'obs_preproc': <function AntConfigModule.obs_preproc at 0x7843ccd9f3b0>,
                           'targ_proc': <function AntConfigModule.targ_proc at 0x7843ccd9f4d0>}},
 'exp_cfg': {'exp_cfg': {'ninit_rollouts': 0,
                         'nrollouts_per_iter': 1,
                         'ntrain_iters': 2},
             'log_cfg': DotMap(logdir='log'),
             'sim_cfg': {'env': <mbbl.env.gym_env.walker.env object at 0x7843ccd95b10>,
                         'seed_eval': 0,
                         'seed_train': 1,
                         'task_hor': 200}}}
2024-11-09 22:13:27,220 - INFO - Using seed 1 for training
2024-11-09 22:13:27,221 - INFO - Created an ensemble of 5 neural networks with variance predictions.
2024-11-09 22:13:28,369 - INFO - policy training learning rate: 0.001
2024-11-09 22:13:32,920 - INFO - Created an MPC controller, prop mode E, 1 particles. Ignoring variance.
2024-11-09 22:13:32,920 - INFO - Trajectory prediction logging is disabled.
2024-11-09 22:28:26,440 - INFO - 
{'ctrl_cfg': {'cem_cfg': {'cem_type': 'DecentCEM',
                          'debug_optimizer': False,
                          'debug_policy': False,
                          'discriminator_act_type': 'leaky_relu',
                          'discriminator_ent_lambda': 0.001,
                          'discriminator_epochs': 40,
                          'discriminator_gradient_penalty_coeff': 10.0,
                          'discriminator_lr': 0.003,
                          'discriminator_minibatch_size': 64,
                          'discriminator_network_shape': [64, 64],
                          'discriminator_norm_type': None,
                          'ensemble_size': 5,
                          'eval_cem_policy': False,
                          'eval_ctrl_type': 'MPC',
                          'gan_type': 'GAN',
                          'init_var': 0.25,
                          'loss_type': 'reverse',
                          'loss_weight': [1, 1],
                          'minibatch_size': 64,
                          'pct_testset': 0.2,
                          'policy_epochs': 100,
                          'policy_lr': 0.001,
                          'policy_lr_weight': 0.2,
                          'policy_network_shape': [64, 64],
                          'policy_weight_decay': 1e-05,
                          'pwcem_init_mean': True,
                          'return_best_sample': False,
                          'seed': 1234,
                          'test_policy': 1,
                          'test_policy_epochs': 1,
                          'training_scheme': 'BC-AR',
                          'training_top_k': 50,
                          'use_prev_sol': True,
                          'zero_weight': 'No'},
              'env': <mbbl.env.gym_env.walker.env object at 0x7a08dfcb3350>,
              'gbp_cfg': DotMap(plan_iter=5, lr=0.03, gbp_type=3),
              'get_display_obs_fn': None,
              'il_cfg': DotMap(expert_amc_dir='/home', use_gt_dynamics=0),
              'mb_cfg': {'activation': 'swish',
                         'do_benchmarking': 'no',
                         'dynamics_lr': 0.001,
                         'mb_batch_size': 32,
                         'mb_epochs': 100,
                         'normalization': 'none'},
              'opt_cfg': {'ac_cost_fn': <function AntConfigModule.ac_cost_fn at 0x7a08dfcb4710>,
                          'cfg': {'alpha': 0.1,
                                  'max_iters': 5,
                                  'num_elites': 10,
                                  'popsize': 100},
                          'init_var': 0.25,
                          'mb_cfg': {'activation': 'swish',
                                     'do_benchmarking': 'no',
                                     'dynamics_lr': 0.001,
                                     'mb_batch_size': 32,
                                     'mb_epochs': 100,
                                     'normalization': 'none'},
                          'mode': 'DecentCEM',
                          'obs_cost_fn': <function AntConfigModule.obs_cost_fn at 0x7a08dfcb4680>,
                          'plan_hor': 30},
              'prop_cfg': {'mode': 'E',
                           'model_init_cfg': {'model_class': <class 'dmbrl.modeling.models.BNN.BNN'>,
                                              'model_constructor': <bound method AntConfigModule.nn_constructor of <gym_ant.AntConfigModule object at 0x7a08dfcb31d0>>,
                                              'num_nets': 5},
                           'model_train_cfg': {'epochs': 5},
                           'npart': 1,
                           'obs_ac_cost_fn': None,
                           'obs_postproc': <function AntConfigModule.obs_postproc at 0x7a08dfcb4560>,
                           'obs_preproc': <function AntConfigModule.obs_preproc at 0x7a08dfcb44d0>,
                           'targ_proc': <function AntConfigModule.targ_proc at 0x7a08dfcb45f0>}},
 'exp_cfg': {'exp_cfg': {'ninit_rollouts': 0,
                         'nrollouts_per_iter': 1,
                         'ntrain_iters': 2},
             'log_cfg': DotMap(logdir='log'),
             'sim_cfg': {'env': <mbbl.env.gym_env.walker.env object at 0x7a08dfcb3350>,
                         'seed_eval': 0,
                         'seed_train': 1,
                         'task_hor': 200}}}
2024-11-09 22:28:26,441 - INFO - Using seed 1 for training
2024-11-09 22:28:26,441 - INFO - Created an ensemble of 5 neural networks with variance predictions.
2024-11-09 22:28:29,166 - INFO - Created an MPC controller, prop mode E, 1 particles. Ignoring variance.
2024-11-09 22:28:29,166 - INFO - Trajectory prediction logging is disabled.
2024-11-09 22:51:25,530 - INFO - 
{'ctrl_cfg': {'cem_cfg': {'cem_type': 'POPLINA-INIT',
                          'debug_optimizer': False,
                          'debug_policy': False,
                          'discriminator_act_type': 'leaky_relu',
                          'discriminator_ent_lambda': 0.001,
                          'discriminator_epochs': 40,
                          'discriminator_gradient_penalty_coeff': 10.0,
                          'discriminator_lr': 0.003,
                          'discriminator_minibatch_size': 64,
                          'discriminator_network_shape': [64, 64],
                          'discriminator_norm_type': None,
                          'ensemble_size': 5,
                          'eval_cem_policy': False,
                          'eval_ctrl_type': 'MPC',
                          'gan_type': 'GAN',
                          'init_var': 0.25,
                          'loss_type': 'reverse',
                          'loss_weight': [1, 1],
                          'minibatch_size': 64,
                          'pct_testset': 0.2,
                          'policy_epochs': 100,
                          'policy_lr': 0.001,
                          'policy_lr_weight': 0.2,
                          'policy_network_shape': [64, 64],
                          'policy_weight_decay': 1e-05,
                          'pwcem_init_mean': True,
                          'return_best_sample': False,
                          'seed': 1234,
                          'test_policy': 1,
                          'test_policy_epochs': 1,
                          'training_scheme': 'BC-AE',
                          'training_top_k': 50,
                          'use_prev_sol': True,
                          'zero_weight': 'No'},
              'env': <mbbl.env.gym_env.walker.env object at 0x7521b66b23d0>,
              'gbp_cfg': DotMap(plan_iter=5, lr=0.03, gbp_type=3),
              'get_display_obs_fn': None,
              'il_cfg': DotMap(expert_amc_dir='/home', use_gt_dynamics=0),
              'mb_cfg': {'activation': 'swish',
                         'do_benchmarking': 'no',
                         'dynamics_lr': 0.001,
                         'mb_batch_size': 32,
                         'mb_epochs': 100,
                         'normalization': 'none'},
              'opt_cfg': {'ac_cost_fn': <function AntConfigModule.ac_cost_fn at 0x7521b66b3710>,
                          'cfg': {'alpha': 0.1,
                                  'max_iters': 5,
                                  'num_elites': 10,
                                  'popsize': 100},
                          'init_var': 0.25,
                          'mb_cfg': {'activation': 'swish',
                                     'do_benchmarking': 'no',
                                     'dynamics_lr': 0.001,
                                     'mb_batch_size': 32,
                                     'mb_epochs': 100,
                                     'normalization': 'none'},
                          'mode': 'POPLIN-A-E',
                          'obs_cost_fn': <function AntConfigModule.obs_cost_fn at 0x7521b66b3680>,
                          'plan_hor': 30},
              'prop_cfg': {'mode': 'E',
                           'model_init_cfg': {'model_class': <class 'dmbrl.modeling.models.BNN.BNN'>,
                                              'model_constructor': <bound method AntConfigModule.nn_constructor of <gym_ant.AntConfigModule object at 0x7521b66b2250>>,
                                              'num_nets': 5},
                           'model_train_cfg': {'epochs': 5},
                           'npart': 1,
                           'obs_ac_cost_fn': None,
                           'obs_postproc': <function AntConfigModule.obs_postproc at 0x7521b66b3560>,
                           'obs_preproc': <function AntConfigModule.obs_preproc at 0x7521b66b34d0>,
                           'targ_proc': <function AntConfigModule.targ_proc at 0x7521b66b35f0>}},
 'exp_cfg': {'exp_cfg': {'ninit_rollouts': 0,
                         'nrollouts_per_iter': 1,
                         'ntrain_iters': 2},
             'log_cfg': DotMap(logdir='log'),
             'sim_cfg': {'env': <mbbl.env.gym_env.walker.env object at 0x7521b66b23d0>,
                         'seed_eval': 0,
                         'seed_train': 1,
                         'task_hor': 50}}}
2024-11-09 22:51:25,531 - INFO - Using seed 1 for training
2024-11-09 22:51:25,532 - INFO - Created an ensemble of 5 neural networks with variance predictions.
2024-11-09 22:51:26,836 - INFO - policy training learning rate: 0.001
2024-11-09 22:51:27,082 - INFO - policy training learning rate: 0.001
2024-11-09 22:51:27,326 - INFO - policy training learning rate: 0.001
2024-11-09 22:51:27,575 - INFO - policy training learning rate: 0.001
2024-11-09 22:51:27,833 - INFO - policy training learning rate: 0.001
2024-11-09 22:51:53,697 - INFO - Created an MPC controller, prop mode E, 1 particles. Ignoring variance.
2024-11-09 22:51:53,697 - INFO - Trajectory prediction logging is disabled.
